{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\82102\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VADER 사전 다운로드 (최초 한 번만 실행)\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "발견된 모든 CSV 파일: ['user_@Ajay_Bagga_tweets.csv', 'user_@BillAckman_tweets.csv', 'user_@CathieDWood_tweets.csv', 'user_@elonmusk_tweets.csv', 'user_@JDVance_tweets.csv', 'user_@LizAnnSonders_tweets.csv', 'user_@marcorubio_tweets.csv', 'user_@michaelbatnick_tweets.csv', 'user_@RayDalio_tweets.csv', 'user_@SecScottBessent_tweets.csv', 'user_@sundarpichai_tweets.csv', 'user_@tim_cook_tweets.csv', 'user_@WhiteHouse_tweets.csv']\n",
      "총 13개의 파일을 병합합니다.\n",
      "user_@Ajay_Bagga_tweets.csv 읽기 완료 - 530개 행\n",
      "user_@BillAckman_tweets.csv 읽기 완료 - 800개 행\n",
      "user_@CathieDWood_tweets.csv 읽기 완료 - 670개 행\n",
      "user_@elonmusk_tweets.csv 읽기 완료 - 764개 행\n",
      "user_@JDVance_tweets.csv 읽기 완료 - 701개 행\n",
      "user_@LizAnnSonders_tweets.csv 읽기 완료 - 673개 행\n",
      "user_@marcorubio_tweets.csv 읽기 완료 - 806개 행\n",
      "user_@michaelbatnick_tweets.csv 읽기 완료 - 760개 행\n",
      "user_@RayDalio_tweets.csv 읽기 완료 - 725개 행\n",
      "user_@SecScottBessent_tweets.csv 읽기 완료 - 255개 행\n",
      "user_@sundarpichai_tweets.csv 읽기 완료 - 585개 행\n",
      "user_@tim_cook_tweets.csv 읽기 완료 - 838개 행\n",
      "user_@WhiteHouse_tweets.csv 읽기 완료 - 651개 행\n",
      "🎉 총 8758개 행이 병합되었습니다!\n",
      "📊 포함된 사용자 수: 13\n"
     ]
    }
   ],
   "source": [
    "# X_data 디렉토리의 모든 user_CSV 파일들을 병합\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# 모든 user_ CSV 파일 찾기\n",
    "csv_files = glob.glob(\"user_*.csv\")\n",
    "print(f\"발견된 모든 CSV 파일: {csv_files}\")\n",
    "print(f\"총 {len(csv_files)}개의 파일을 병합합니다.\")\n",
    "\n",
    "# 모든 CSV 파일들을 병합\n",
    "dfs = []\n",
    "for file in csv_files:\n",
    "    if os.path.exists(file):\n",
    "        temp_df = pd.read_csv(file)\n",
    "        # 파일명에서 사용자명 추출하여 컬럼 추가\n",
    "        username = file.replace(\"user_\", \"\").replace(\"_tweets.csv\", \"\")\n",
    "        temp_df['username'] = username\n",
    "        dfs.append(temp_df)\n",
    "        print(f\"{file} 읽기 완료 - {len(temp_df)}개 행\")\n",
    "\n",
    "# 모든 데이터프레임 병합\n",
    "if dfs:\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    print(f\"🎉 총 {len(df)}개 행이 병합되었습니다!\")\n",
    "    print(f\"📊 포함된 사용자 수: {len(df['username'].unique())}\")\n",
    "else:\n",
    "    print(\"읽을 수 있는 파일이 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL 제거 함수\n",
    "def remove_urls(text):\n",
    "    return re.sub(r'https?://\\S+', '', text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL 제거 적용\n",
    "df['full_text'] = df['full_text'].apply(remove_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Local\\Temp\\ipykernel_36128\\1257741985.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['full_text'].replace('', pd.NA, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# 빈 문자열 → NaN\n",
    "df['full_text'].replace('', pd.NA, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN 제거 (필요 시)\n",
    "df.dropna(subset=['full_text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "날짜 형식 변환 중...\n",
      "날짜 형식 변환 및 정렬 완료!\n",
      "날짜 범위: 2020-01-17 01:05:39 ~ 2025-06-16 04:36:37\n",
      "\n",
      "결과 확인:\n",
      "           created_at                                          full_text  \\\n",
      "0 2025-06-16 04:36:37  1. Iran produces around 3.3mn barrels per day ...   \n",
      "1 2025-06-16 03:40:49             Today at Apple. #F1TheMovie #Severance   \n",
      "2 2025-06-16 03:04:38  Two countries, separated by 700 kms from each ...   \n",
      "3 2025-06-16 03:01:08  BREAKING: Iranian opposition Telegram channels...   \n",
      "4 2025-06-16 02:50:54  26 now.   Note the swing due east at the edge ...   \n",
      "\n",
      "      username  \n",
      "0  @Ajay_Bagga  \n",
      "1    @tim_cook  \n",
      "2  @Ajay_Bagga  \n",
      "3  @BillAckman  \n",
      "4  @BillAckman  \n"
     ]
    }
   ],
   "source": [
    "# created_at 컬럼 날짜 형식 변환 함수\n",
    "def convert_date_format(date_str):\n",
    "    try:\n",
    "        # \"Mon Jun 16 02:50:54 +0000 2025\" 형식을 파싱\n",
    "        dt = pd.to_datetime(date_str, format='%a %b %d %H:%M:%S %z %Y')\n",
    "        # \"2025-06-13 23:00:00\" 형식으로 변환 (timezone 제거)\n",
    "        return dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    except:\n",
    "        return date_str\n",
    "\n",
    "# created_at 컬럼 형식 변환\n",
    "print(\"날짜 형식 변환 중...\")\n",
    "df['created_at'] = df['created_at'].apply(convert_date_format)\n",
    "\n",
    "# created_at을 datetime 타입으로 변환\n",
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "\n",
    "# created_at 기준으로 내림차순 정렬 (최신 순)\n",
    "df = df.sort_values(by='created_at', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"날짜 형식 변환 및 정렬 완료!\")\n",
    "print(f\"날짜 범위: {df['created_at'].min()} ~ {df['created_at'].max()}\")\n",
    "print(\"\\n결과 확인:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SentimentIntensityAnalyzer 초기화\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감성 분석 함수\n",
    "def analyze_sentiment(text):\n",
    "    scores = sia.polarity_scores(text)\n",
    "    compound = scores['compound']\n",
    "    if compound >= 0.05:\n",
    "        sentiment = 'positive'\n",
    "    elif compound <= -0.05:\n",
    "        sentiment = 'negative'\n",
    "    else:\n",
    "        sentiment = 'neutral'\n",
    "    return pd.Series([sentiment, scores['neg'], scores['neu'], scores['pos']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감성 분석 결과 적용 및 컬럼 추가\n",
    "df[['sentiment', 'neg', 'neu', 'pos']] = df['full_text'].apply(analyze_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 컬럼만 추출 (username 컬럼도 포함)\n",
    "df = df[['created_at', 'full_text', 'username', 'sentiment', 'neg', 'neu', 'pos']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결과가 merged_tweets_with_sentiment.csv에 저장되었습니다.\n",
      "총 8594개의 트윗이 처리되었습니다.\n",
      "포함된 사용자: ['@Ajay_Bagga', '@BillAckman', '@CathieDWood', '@JDVance', '@LizAnnSonders', '@RayDalio', '@SecScottBessent', '@WhiteHouse', '@elonmusk', '@marcorubio', '@michaelbatnick', '@sundarpichai', '@tim_cook']\n",
      "날짜 범위: 2020-01-17 01:05:39 ~ 2025-06-16 04:36:37\n"
     ]
    }
   ],
   "source": [
    "# 결과 저장\n",
    "output_filename = \"merged_tweets_with_sentiment.csv\"\n",
    "df.to_csv(output_filename, index=False)\n",
    "print(f\"결과가 {output_filename}에 저장되었습니다.\")\n",
    "print(f\"총 {len(df)}개의 트윗이 처리되었습니다.\")\n",
    "print(f\"포함된 사용자: {sorted(df['username'].unique())}\")\n",
    "print(f\"날짜 범위: {df['created_at'].min()} ~ {df['created_at'].max()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
