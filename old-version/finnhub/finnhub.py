#!/usr/bin/env python3
import requests
import pandas as pd
import datetime
import os
from dotenv import load_dotenv
import yfinance as yf
import time

# .env ì„¤ì • ë¡œë“œ
load_dotenv()
FINHUB_API_KEY = os.getenv("finhub")  # ë³€ìˆ˜ëª…ì€ 'finnhub' ì•„ë‹Œ 'finhub'

# API í˜¸ì¶œ ì œí•œ (60 calls/minute)
API_CALLS_PER_MINUTE = 60
DELAY_BETWEEN_CALLS = 60.0 / API_CALLS_PER_MINUTE  # 1ì´ˆ ê°„ê²©


def safe_datetime_conversion(timestamp):
    """
    íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ì•ˆì „í•˜ê²Œ datetimeìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    Out of bounds nanosecond timestamp ì˜¤ë¥˜ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
    """
    if not timestamp or timestamp == 0:
        return None
    
    try:
        # ìœ ë‹‰ìŠ¤ íƒ€ì„ìŠ¤íƒ¬í”„ ë²”ìœ„ í™•ì¸ (1970-01-01 ì´í›„)
        if timestamp < 0:
            return None
            
        # ë„ˆë¬´ í° ê°’ í™•ì¸ (2262ë…„ ì´í›„ëŠ” pandasì—ì„œ ì²˜ë¦¬ ë¶ˆê°€)
        if timestamp > 9223372036:  # 2262-04-11 ì •ë„
            return None
            
        # ì •ìƒì ì¸ ë³€í™˜ ì‹œë„
        return pd.to_datetime(timestamp, unit='s')
        
    except (ValueError, OutOfBoundsDatetime, OverflowError):
        # ë³€í™˜ ì‹¤íŒ¨ ì‹œ None ë°˜í™˜
        return None
    except Exception:
        # ê¸°íƒ€ ì˜ˆì™¸ ì‹œ None ë°˜í™˜
        return None


# Finnhubì—ì„œ íšŒì‚¬ ë‰´ìŠ¤ ìˆ˜ì§‘ (ìµœì í™”ëœ ë²„ì „ - ëŒ€ëŸ‰ ìˆ˜ì§‘)
def fetch_finnhub_news_extended(symbol: str = "GOOGL", start_date: str = "2025-06-14", days_per_request: int = 30) -> pd.DataFrame:
    """
    í•˜ë‚˜ì˜ ì‹¬ë³¼ì— ëŒ€í•´ ìµœëŒ€í•œ ë§ì€ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    ë‚ ì§œ êµ¬ê°„ì„ ë‚˜ëˆ„ì–´ì„œ ì—¬ëŸ¬ ë²ˆ API í˜¸ì¶œí•˜ì—¬ ë” ë§ì€ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    
    Args:
        symbol: ì£¼ì‹ ì‹¬ë³¼ (ì˜ˆ: "AAPL")
        start_date: ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD)
        days_per_request: í•œ ë²ˆì˜ API í˜¸ì¶œë‹¹ ìˆ˜ì§‘í•  ì¼ìˆ˜ (ê¸°ë³¸: 30ì¼)
    """
    if not FINHUB_API_KEY:
        print("[ERROR] Finnhub API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        return pd.DataFrame()

    url = "https://finnhub.io/api/v1/company-news"
    
    try:
        start_date_obj = datetime.datetime.strptime(start_date, "%Y-%m-%d").date()
        today = datetime.date.today()
        
        print(f"[INFO] ìš”ì²­ ì‹œì‘ ë‚ ì§œ: {start_date_obj}")
        print(f"[INFO] í˜„ì¬ ë‚ ì§œ: {today}")
        
        # Free Tier ì œí•œì„ ë„˜ì–´ì„œ ìµœëŒ€í•œ ë§ì´ ìˆ˜ì§‘ ì‹œë„
        two_years_ago = today - datetime.timedelta(days=730)  # 2ë…„ ì „
        three_years_ago = today - datetime.timedelta(days=1095)  # 3ë…„ ì „
        
        print(f"[INFO] ğŸš€ Free Tier ì œí•œ ëŒíŒŒ ì‹œë„: 2-3ë…„ê°„ ë‰´ìŠ¤ ìˆ˜ì§‘ì„ ì‹œë„í•©ë‹ˆë‹¤!")
        print(f"[INFO] 2ë…„ ì „ ë‚ ì§œ: {two_years_ago}")
        print(f"[INFO] 3ë…„ ì „ ë‚ ì§œ: {three_years_ago}")
        
        # 3ë…„ ì „ë¶€í„° í˜„ì¬ê¹Œì§€ë¡œ ì‹œë„ (APIê°€ ì–´ë””ê¹Œì§€ í—ˆìš©í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸)
        actual_start = three_years_ago
        actual_end = today
        
        print(f"[INFO] {symbol} ë‰´ìŠ¤ ëŒ€ëŸ‰ ìˆ˜ì§‘ ì‹œì‘ (ì œí•œ ëŒíŒŒ ì‹œë„)")
        print(f"[INFO] ì‹¤ì œ ìˆ˜ì§‘ ê¸°ê°„: {actual_start.isoformat()} ~ {actual_end.isoformat()}")
        print(f"[INFO] ìˆ˜ì§‘ ê¸°ê°„: {(actual_end - actual_start).days}ì¼ (ì•½ 3ë…„)")
        print(f"[INFO] ì˜ˆìƒ API í˜¸ì¶œ íšŸìˆ˜: {(actual_end - actual_start).days // days_per_request + 1}íšŒ")
        print(f"[WARNING] APIê°€ ì œí•œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ ì¤‘...")
        
    except ValueError:
        print(f"[ERROR] ì˜ëª»ëœ ë‚ ì§œ í˜•ì‹: {start_date}. YYYY-MM-DD í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
        return pd.DataFrame()

    all_articles = []
    current_date = actual_start
    request_count = 0
    
    while current_date < actual_end:
        # ê° ìš”ì²­ì˜ ì¢…ë£Œ ë‚ ì§œ ê³„ì‚°
        period_end = min(current_date + datetime.timedelta(days=days_per_request), actual_end)
        
        params = {
            "symbol": symbol,
            "from": current_date.isoformat(),
            "to": period_end.isoformat(),
            "token": FINHUB_API_KEY
        }
        
        try:
            request_count += 1
            print(f"[INFO] API í˜¸ì¶œ {request_count}: {current_date.isoformat()} ~ {period_end.isoformat()}")
            
            # API í˜¸ì¶œ ì œí•œì„ ìœ„í•œ ë”œë ˆì´
            time.sleep(DELAY_BETWEEN_CALLS)
            
            res = requests.get(url, params=params, timeout=30)
            
            if res.status_code == 429:
                print(f"[WARNING] API í˜¸ì¶œ ì œí•œ ë„ë‹¬. ë” ê¸´ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                time.sleep(10)
                res = requests.get(url, params=params, timeout=30)
            
            if res.status_code == 403:
                print(f"[ERROR] API ì ‘ê·¼ ê±°ë¶€ (ê¸°ê°„: {current_date} ~ {period_end}): Free Tier ì œí•œ ë„ë‹¬ ê°€ëŠ¥ì„±")
                print(f"[INFO] í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ ê¸°ì‚¬: {len(all_articles)}ê°œ")
                break
            
            if res.status_code != 200:
                print(f"[WARNING] API ìš”ì²­ ì‹¤íŒ¨ (ê¸°ê°„: {current_date} ~ {period_end}): HTTP {res.status_code}")
                print(f"[INFO] ì‘ë‹µ ë‚´ìš©: {res.text[:200]}...")
                
                # 429 (Too Many Requests)ê°€ ì•„ë‹ˆë¼ë©´ ê³„ì† ì§„í–‰
                if res.status_code != 429:
                    current_date = period_end + datetime.timedelta(days=1)
                    continue
                else:
                    print(f"[INFO] í˜¸ì¶œ ì œí•œìœ¼ë¡œ ì¸í•œ ëŒ€ê¸°...")
                    time.sleep(30)
                    continue

            data = res.json()
            
            if not isinstance(data, list):
                print(f"[WARNING] ì˜ˆìƒê³¼ ë‹¤ë¥¸ ì‘ë‹µ í˜•ì‹ (ê¸°ê°„: {current_date} ~ {period_end})")
                if isinstance(data, dict) and 'error' in data:
                    print(f"[ERROR] API ì˜¤ë¥˜: {data['error']}")
                    if 'limit' in data['error'].lower():
                        print(f"[INFO] Free Tier ì œí•œ ë„ë‹¬. í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘: {len(all_articles)}ê°œ")
                        break
                current_date = period_end + datetime.timedelta(days=1)
                continue

            # í•´ë‹¹ ê¸°ê°„ì˜ ë‰´ìŠ¤ ìˆ˜ì§‘
            period_articles = []
            for item in data:
                # ì•ˆì „í•œ datetime ë³€í™˜ ì‚¬ìš©
                pub_date = safe_datetime_conversion(item.get("datetime"))
                
                article = {
                    "id": item.get("id"),
                    "title": item.get("headline", ""),
                    "summary": item.get("summary", ""),
                    "link": item.get("url", ""),
                    "publisher": item.get("publisher", ""),
                    "category": item.get("category", ""),
                    "pubDate": pub_date,
                    "image": item.get("image", ""),
                    "related": item.get("related", ""),
                    "source": item.get("source", ""),
                    "collection_period": f"{current_date.isoformat()}_{period_end.isoformat()}"
                }
                period_articles.append(article)
            
            all_articles.extend(period_articles)
            print(f"[SUCCESS] ê¸°ê°„ë³„ ìˆ˜ì§‘: {len(period_articles)}ê°œ ê¸°ì‚¬ (ì´ {len(all_articles)}ê°œ)")
            
        except Exception as e:
            print(f"[ERROR] API í˜¸ì¶œ ì˜¤ë¥˜ (ê¸°ê°„: {current_date} ~ {period_end}): {e}")
            if "limit" in str(e).lower() or "403" in str(e):
                print(f"[INFO] Free Tier ì œí•œ ë„ë‹¬ ê°€ëŠ¥ì„±. í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘: {len(all_articles)}ê°œ")
                break
        
        # ë‹¤ìŒ ê¸°ê°„ìœ¼ë¡œ ì´ë™
        current_date = period_end + datetime.timedelta(days=1)
        
        # API í˜¸ì¶œ ì œí•œ ë°©ì§€ë¥¼ ìœ„í•œ ì¶”ê°€ ëŒ€ê¸°
        if request_count % 10 == 0:  # 10ë²ˆ í˜¸ì¶œë§ˆë‹¤ ì¶”ê°€ ëŒ€ê¸°
            print(f"[INFO] API ì œí•œ ë°©ì§€ë¥¼ ìœ„í•œ ëŒ€ê¸°... (í˜„ì¬ê¹Œì§€ {len(all_articles)}ê°œ ìˆ˜ì§‘)")
            time.sleep(2)

    # ì „ì²´ ê²°ê³¼ ì²˜ë¦¬
    if all_articles:
        df = pd.DataFrame(all_articles)
        
        # ì¤‘ë³µ ì œê±° (ID, ì œëª©, ë§í¬ ê¸°ì¤€)
        before_dedup = len(df)
        df = df.drop_duplicates(subset=['id', 'title', 'link'])
        after_dedup = len(df)
        
        if before_dedup != after_dedup:
            print(f"[INFO] ì¤‘ë³µ ê¸°ì‚¬ ì œê±°: {before_dedup - after_dedup}ê°œ")
        
        # ë‚ ì§œìˆœ ì •ë ¬ (ìµœì‹ ìˆœ) - None ê°’ ì²˜ë¦¬
        df = df.sort_values('pubDate', ascending=False, na_position='last')
        
        print(f"[SUCCESS] {symbol} ì´ {len(df)}ê°œì˜ ë‰´ìŠ¤ ê¸°ì‚¬ ìˆ˜ì§‘ ì™„ë£Œ!")
        print(f"[INFO] ì´ API í˜¸ì¶œ íšŸìˆ˜: {request_count}íšŒ")
        
        return df
    else:
        print(f"[WARNING] {symbol}ì— ëŒ€í•œ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()


# yfinance ì£¼ê°€ ë°ì´í„°
def fetch_stock_data(ticker_symbol: str, period: str = '1y', interval: str = '1d') -> pd.DataFrame:
    try:
        df = yf.download(
            tickers=ticker_symbol,
            period=period,
            interval=interval,
            auto_adjust=False,
            progress=False
        )
        if df.empty:
            return pd.DataFrame()
        df = df.reset_index()
        df = df.rename(columns={'Adj Close': 'Adj_Close'})
        return df[['Date', 'Open', 'High', 'Low', 'Close', 'Adj_Close', 'Volume']]
    except Exception as e:
        print(f"[ERROR] ì£¼ì‹ ë°ì´í„° ì˜¤ë¥˜: {e}")
        return pd.DataFrame()


if __name__ == "__main__":
    # ëŒ€ëŸ‰ ë‰´ìŠ¤ ìˆ˜ì§‘í•  ë‹¨ì¼ ì‹¬ë³¼ ì„¤ì •
    target_symbol = "GOOGL"  # ì›í•˜ëŠ” ì‹¬ë³¼ë¡œ ë³€ê²½ ê°€ëŠ¥ (ì˜ˆ: MSFT, GOOGL, AMZN, TSLA, META, NVDA ë“±)
    start_date = "2025-06-13"  # ì°¸ê³ ìš© (ì‹¤ì œë¡œëŠ” 1ë…„ ì „ë¶€í„° ìë™ ìˆ˜ì§‘)
    days_per_request = 7  # í•œ ë²ˆì˜ API í˜¸ì¶œë‹¹ 7ì¼ì”© ìˆ˜ì§‘ (ë” ë§ì€ API í˜¸ì¶œë¡œ ìµœëŒ€ ìˆ˜ì§‘)
    
    print(f"ğŸš€ {target_symbol} ë‰´ìŠ¤ ëŒ€ëŸ‰ ìˆ˜ì§‘ ì‹œì‘!")
    print(f"ğŸ“… ì°¸ê³  ë‚ ì§œ: {start_date} (ì‹¤ì œë¡œëŠ” 3ë…„ ì „ë¶€í„° ìˆ˜ì§‘ ì‹œë„)")
    print(f"ğŸ“Š ìˆ˜ì§‘ ë°©ì‹: {days_per_request}ì¼ì”© êµ¬ê°„ë³„ ìˆ˜ì§‘")
    print(f"â±ï¸  API ì œí•œ: {API_CALLS_PER_MINUTE}íšŒ/ë¶„")
    print(f"ğŸ¯ ëª©í‘œ: ğŸš€ Free Tier ì œí•œ ëŒíŒŒ ì‹œë„ - ìµœëŒ€ 3ë…„ê°„ ë‰´ìŠ¤ ìˆ˜ì§‘!")
    print(f"âš ï¸  ì£¼ì˜: APIê°€ ì œí•œì„ ê±¸ ìˆ˜ ìˆìœ¼ë‹ˆ ì‹¤í—˜ì  ìˆ˜ì§‘ì…ë‹ˆë‹¤.")
    print("="*60)
    
    # í™•ì¥ëœ ë‰´ìŠ¤ ìˆ˜ì§‘ í•¨ìˆ˜ ì‚¬ìš©
    df_extended_news = fetch_finnhub_news_extended(
        symbol=target_symbol, 
        start_date=start_date,
        days_per_request=days_per_request
    )
    
    if not df_extended_news.empty:
        print(f"\nğŸ‰ {target_symbol} ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ!")
        print(f"ğŸ“° ì´ ìˆ˜ì§‘ ê¸°ì‚¬ ìˆ˜: {len(df_extended_news)}ê°œ")
        
        # ë‚ ì§œë³„ ê¸°ì‚¬ ë¶„í¬ ë¶„ì„ (ìœ íš¨í•œ ë‚ ì§œë§Œ)
        if 'pubDate' in df_extended_news.columns:
            valid_dates = df_extended_news[df_extended_news['pubDate'].notna()].copy()
            if not valid_dates.empty:
                valid_dates['date_only'] = valid_dates['pubDate'].dt.date
                date_counts = valid_dates['date_only'].value_counts().sort_index()
                print(f"ğŸ“ˆ ìˆ˜ì§‘ ê¸°ê°„: {date_counts.index.min()} ~ {date_counts.index.max()}")
                print(f"ğŸ“Š í‰ê·  ì¼ì¼ ê¸°ì‚¬ ìˆ˜: {date_counts.mean():.1f}ê°œ")
                print(f"ğŸ“… ìœ íš¨í•œ ë‚ ì§œ ê¸°ì‚¬: {len(valid_dates)}ê°œ / ì „ì²´ {len(df_extended_news)}ê°œ")
        
        # ìµœì‹  ê¸°ì‚¬ 10ê°œ ë¯¸ë¦¬ë³´ê¸°
        print(f"\nğŸ“° ìµœì‹  ë‰´ìŠ¤ ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 10ê°œ)")
        print("-" * 80)
        for i, row in df_extended_news.head(10).iterrows():
            pub_date = row['pubDate'].strftime('%Y-%m-%d %H:%M') if pd.notna(row['pubDate']) else 'N/A'
            title = row['title'][:60] + "..." if len(row['title']) > 60 else row['title']
            publisher = row['publisher'] if row['publisher'] else row['source']
            print(f"{i+1:2d}. [{publisher}] {title}")
            print(f"    ğŸ“… {pub_date} | ğŸ”— {row['link'][:50]}...")
            print()
        
        # CSV íŒŒì¼ë¡œ ì €ì¥
        today = datetime.date.today().isoformat()
        filename = f"{target_symbol}_extended_news_{today}.csv"
        df_extended_news.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"ğŸ’¾ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filename}")
        
        # ë°œí–‰ì²˜ë³„ í†µê³„
        print(f"\nğŸ“Š ë°œí–‰ì²˜ë³„ ê¸°ì‚¬ ìˆ˜ í†µê³„ (ìƒìœ„ 10ê°œ)")
        print("-" * 40)
        publisher_col = 'publisher' if df_extended_news['publisher'].notna().any() else 'source'
        publisher_counts = df_extended_news[publisher_col].value_counts()
        for publisher, count in publisher_counts.head(10).items():
            if publisher:  # ë¹ˆ ê°’ì´ ì•„ë‹Œ ê²½ìš°ë§Œ
                print(f"{publisher:25s}: {count:3d}ê°œ")
        
        # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„ (ìˆëŠ” ê²½ìš°)
        if 'category' in df_extended_news.columns and df_extended_news['category'].notna().any():
            print(f"\nğŸ·ï¸  ì¹´í…Œê³ ë¦¬ë³„ ê¸°ì‚¬ ìˆ˜")
            print("-" * 30)
            category_counts = df_extended_news['category'].value_counts()
            for category, count in category_counts.items():
                if category:
                    print(f"{category:20s}: {count:3d}ê°œ")
                    
    else:
        print(f"âŒ {target_symbol} ë‰´ìŠ¤ ìˆ˜ì§‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        print("ğŸ”§ ê°€ëŠ¥í•œ í•´ê²° ë°©ë²•:")
        print("   1. API í‚¤ í™•ì¸ (.env íŒŒì¼ì˜ 'finhub' ë³€ìˆ˜)")
        print("   2. ì¸í„°ë„· ì—°ê²° í™•ì¸")  
        print("   3. ì‹¬ë³¼ëª… í™•ì¸ (ë¯¸êµ­ ìƒì¥ ê¸°ì—…ë§Œ ì§€ì›)")
        print("   4. ë‚ ì§œ ë²”ìœ„ ì¡°ì •")
    
    print("\n" + "="*60)
    print("ğŸ“‹ ìˆ˜ì§‘ ì™„ë£Œ ìš”ì•½")
    print("="*60)
    print(f"ğŸ¢ ëŒ€ìƒ ê¸°ì—…: {target_symbol}")
    print(f"ğŸ“… ìˆ˜ì§‘ ë‚ ì§œ: {start_date}")
    print(f"ğŸ“Š ì´ ê¸°ì‚¬ ìˆ˜: {len(df_extended_news) if not df_extended_news.empty else 0}ê°œ")
    print(f"ğŸ’¾ ì €ì¥ íŒŒì¼: {filename if not df_extended_news.empty else 'N/A'}")
