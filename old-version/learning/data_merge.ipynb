{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2ì§„ë¶„ë¥˜ (0.02, -0.02 ê¸°ì¤€ ë¶„ë¥˜)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_stock_and_news(stock_path, news_path):\n",
    "    stock = pd.read_csv(stock_path, parse_dates=[\"Datetime\"])\n",
    "    news = pd.read_csv(news_path, parse_dates=[\"pubDate\"])\n",
    "\n",
    "    stock[\"Datetime\"] = stock[\"Datetime\"].dt.tz_localize(None)\n",
    "    news[\"pubDate\"] = news[\"pubDate\"].dt.tz_localize(None)\n",
    "\n",
    "    # ì •ë ¬ ë° ì œì™¸ ì—´ ì œê±°\n",
    "    stock = stock.sort_values(\"Datetime\").reset_index(drop=True)\n",
    "    stock = stock.drop(columns=[col for col in stock.columns if col.startswith(\"Is_\")])\n",
    "\n",
    "    return stock, news\n",
    "\n",
    "\n",
    "def make_binary_merged_df(stock_df, news_df, company):\n",
    "    rows = []\n",
    "\n",
    "    for _, news_row in news_df.iterrows():\n",
    "        news_time = news_row[\"pubDate\"]\n",
    "\n",
    "        # ë‰´ìŠ¤ ì´í›„ ê°€ìž¥ ê°€ê¹Œìš´ ì£¼ê°€\n",
    "        future_row = stock_df[stock_df[\"Datetime\"] > news_time].head(1)\n",
    "        if future_row.empty:\n",
    "            continue\n",
    "\n",
    "        target_row = future_row.iloc[0]\n",
    "        target_return = target_row.get(\"Returns\", None)\n",
    "        if pd.isna(target_return):\n",
    "            continue\n",
    "\n",
    "        # ê³¼ê±° 5ê°œ\n",
    "        past_rows = stock_df[stock_df[\"Datetime\"] < target_row[\"Datetime\"]].tail(5)\n",
    "        if len(past_rows) < 5:\n",
    "            continue\n",
    "\n",
    "        if target_return >= 0.01:\n",
    "            label = 1\n",
    "        elif target_return <= -0.01:\n",
    "            label = 0\n",
    "        else:\n",
    "            continue  # ê¸°ì¤€ ë¯¸ë‹¬ì¸ ê²½ìš°ëŠ” ë¬´ì‹œ\n",
    "\n",
    "        row = {\n",
    "            \"company\": company,\n",
    "            \"news_time\": news_time,\n",
    "            \"target_return\": target_return,\n",
    "            \"target\": label,\n",
    "            \"finbert_positive\": news_row[\"finbert_positive\"],\n",
    "            \"finbert_neutral\": news_row[\"finbert_neutral\"],\n",
    "            \"finbert_negative\": news_row[\"finbert_negative\"]\n",
    "        }\n",
    "\n",
    "        for i, (_, p_row) in enumerate(past_rows.iterrows(), 1):\n",
    "            for col in stock_df.columns:\n",
    "                if col == \"Datetime\":\n",
    "                    continue\n",
    "                row[f\"x{i}_{col}\"] = p_row[col]\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news_stock_binary_classification.csv ì €ìž¥ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"./\"  # ì••ì¶• í’€ë¦° í´ë” ê¸°ì¤€\n",
    "companies = {\n",
    "    \"AAPL\": (\"AAPL_1hour_data_365days.csv\", \"apple_finbert_finnhub.csv\"),\n",
    "    \"AMZN\": (\"AMZN_1hour_data_365days.csv\", \"amazon_finbert_finnhub.csv\"),\n",
    "    \"GOOGL\": (\"GOOGL_1hour_data_365days.csv\", \"google_finbert_finnhub.csv\"),\n",
    "    \"MSFT\": (\"MSFT_1hour_data_365days.csv\", \"microsoft_finbert_finnhub.csv\"),\n",
    "    \"TSLA\": (\"TSLA_1hour_data_365days.csv\", \"tesla_finbert_finnhub.csv\"),\n",
    "}\n",
    "\n",
    "dfs = []\n",
    "for company, (stock_file, news_file) in companies.items():\n",
    "    stock_path = os.path.join(base_dir, stock_file)\n",
    "    news_path = os.path.join(base_dir, news_file)\n",
    "    if not os.path.exists(stock_path) or not os.path.exists(news_path):\n",
    "        continue\n",
    "\n",
    "    stock_df, news_df = load_stock_and_news(stock_path, news_path)\n",
    "    merged_df = make_binary_merged_df(stock_df, news_df, company)\n",
    "    dfs.append(merged_df)\n",
    "\n",
    "# ìµœì¢… ë³‘í•©\n",
    "final_df = pd.concat(dfs, ignore_index=True)\n",
    "final_df.to_csv(\"news_stock_binary_classification.csv\", index=False)\n",
    "print(\"news_stock_binary_classification.csv ì €ìž¥ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š í´ëž˜ìŠ¤ ë¶„í¬ (ìƒ˜í”Œ ìˆ˜):\n",
      "target\n",
      "0    2428\n",
      "1    2519\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ðŸ“Š í´ëž˜ìŠ¤ ë¹„ìœ¨ (%):\n",
      "target\n",
      "0    49.08 %\n",
      "1    50.92 %\n",
      "Name: proportion, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV íŒŒì¼ ë¡œë“œ\n",
    "df = pd.read_csv(\"news_stock_binary_classification.csv\")\n",
    "df.head(5)\n",
    "# ë¼ë²¨ ë¶„í¬ í™•ì¸\n",
    "label_counts = df[\"target\"].value_counts().sort_index()\n",
    "label_ratio = df[\"target\"].value_counts(normalize=True).sort_index() * 100\n",
    "\n",
    "# ì¶œë ¥\n",
    "print(\"ðŸ“Š í´ëž˜ìŠ¤ ë¶„í¬ (ìƒ˜í”Œ ìˆ˜):\")\n",
    "print(label_counts)\n",
    "\n",
    "print(\"\\nðŸ“Š í´ëž˜ìŠ¤ ë¹„ìœ¨ (%):\")\n",
    "print(label_ratio.round(2).astype(str) + \" %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def load_stock_and_news(stock_path, news_path):\n",
    "    stock = pd.read_csv(stock_path, parse_dates=[\"Datetime\"])\n",
    "    news = pd.read_csv(news_path, parse_dates=[\"pubDate\"])\n",
    "\n",
    "    stock[\"Datetime\"] = stock[\"Datetime\"].dt.tz_localize(None)\n",
    "    news[\"pubDate\"] = news[\"pubDate\"].dt.tz_localize(None)\n",
    "\n",
    "    stock = stock.sort_values(\"Datetime\").reset_index(drop=True)\n",
    "    stock = stock.drop(columns=[col for col in stock.columns if col.startswith(\"Is_\")])\n",
    "\n",
    "    return stock, news\n",
    "\n",
    "def classify_context(timestamp):\n",
    "    hour, minute = timestamp.hour, timestamp.minute\n",
    "    if hour < 9 or (hour == 9 and minute < 30):\n",
    "        return \"premarket\"\n",
    "    elif 9 <= hour < 16:\n",
    "        return \"intraday\"\n",
    "    else:\n",
    "        return \"aftermarket\"\n",
    "\n",
    "def make_binary_merged_df(stock_df, news_df, company):\n",
    "    rows = []\n",
    "\n",
    "    for _, news_row in news_df.iterrows():\n",
    "        news_time = news_row[\"pubDate\"]\n",
    "        context = classify_context(news_time)\n",
    "\n",
    "        future_row = stock_df[stock_df[\"Datetime\"] > news_time].head(1)\n",
    "        if future_row.empty:\n",
    "            continue\n",
    "\n",
    "        target_row = future_row.iloc[0]\n",
    "        target_return = target_row.get(\"Returns\", None)\n",
    "        if pd.isna(target_return):\n",
    "            continue\n",
    "\n",
    "        past_rows = stock_df[stock_df[\"Datetime\"] < target_row[\"Datetime\"]].tail(5)\n",
    "        if len(past_rows) < 5:\n",
    "            continue\n",
    "\n",
    "        if target_return >= 0.01:\n",
    "            label = 1\n",
    "        elif target_return <= -0.01:\n",
    "            label = 0\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        row = {\n",
    "            \"company\": company,\n",
    "            \"news_time\": news_time,\n",
    "            \"context\": context,\n",
    "            \"target_return\": target_return,\n",
    "            \"target\": label,\n",
    "            \"finbert_positive\": news_row[\"finbert_positive\"],\n",
    "            \"finbert_neutral\": news_row[\"finbert_neutral\"],\n",
    "            \"finbert_negative\": news_row[\"finbert_negative\"]\n",
    "        }\n",
    "\n",
    "        for i, (_, p_row) in enumerate(past_rows.iterrows(), 1):\n",
    "            for col in stock_df.columns:\n",
    "                if col == \"Datetime\":\n",
    "                    continue\n",
    "                row[f\"x{i}_{col}\"] = p_row[col]\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"./\"\n",
    "companies = {\n",
    "    \"AAPL\": (\"AAPL_1hour_data_365days.csv\", \"apple_finbert_finnhub.csv\"),\n",
    "    \"AMZN\": (\"AMZN_1hour_data_365days.csv\", \"amazon_finbert_finnhub.csv\"),\n",
    "    \"GOOGL\": (\"GOOGL_1hour_data_365days.csv\", \"google_finbert_finnhub.csv\"),\n",
    "    \"MSFT\": (\"MSFT_1hour_data_365days.csv\", \"microsoft_finbert_finnhub.csv\"),\n",
    "    \"TSLA\": (\"TSLA_1hour_data_365days.csv\", \"tesla_finbert_finnhub.csv\"),\n",
    "}\n",
    "\n",
    "dfs = []\n",
    "for company, (stock_file, news_file) in companies.items():\n",
    "    stock_path = os.path.join(base_dir, stock_file)\n",
    "    news_path = os.path.join(base_dir, news_file)\n",
    "    if not os.path.exists(stock_path) or not os.path.exists(news_path):\n",
    "        continue\n",
    "\n",
    "    stock_df, news_df = load_stock_and_news(stock_path, news_path)\n",
    "    merged_df = make_binary_merged_df(stock_df, news_df, company)\n",
    "    dfs.append(merged_df)\n",
    "\n",
    "final_df = pd.concat(dfs, ignore_index=True)\n",
    "final_df.to_csv(\"news_stock_binary_classification.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonProject1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
